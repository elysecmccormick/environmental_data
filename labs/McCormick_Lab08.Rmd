---
title: 'Lab 08: Modeling Data 1'
author: "Elyse McCormick"
date: "`r Sys.Date()`"
output: html_document
subtitle: "Analysis of Environmental Data"
---

**Q1 (1 pt.): Calculate the standard deviation of the differences in mean flipper length from your bootstrap simulation. Show the R-code you used to find do the calculation.**

```{r}
require(simpleboot)
require(palmerpenguins)
set.seed(10000)
sampleA <- droplevels(subset(penguins, species == "Adelie"))
adelieflip <- sampleA$flipper_length_mm
sampleC <- droplevels(subset(penguins, species == "Chinstrap"))
chinflip <- sampleC$flipper_length_mm

pen.boot <- 
  two.boot(na.omit(adelieflip), na.omit(chinflip), mean, R = 10000, student = FALSE, weights = NULL)

sd(pen.boot$t)
```

**Q2 (2 pts.): Include your histogram of bootstrapped differences in your lab report (you donâ€™t need to show the R-code but make sure your plot includes appropriate title, axes, etc.).**

```{r echo=TRUE}

hist(pen.boot$t, xlab = "bootstrap t values", 
     main = "Distribution of Boostrapped Values of Flipper Length", 
     col = "skyblue")
```

**Q3 (2 pts.): What was the 95% bootstrap CI you calculated using quantile()? Show the R-code you used to answer the question.**

```{r}
quantile(pen.boot$t,c(0.025, 0.975))
```

**Q4 (4 pts.): Do you think the resampled differences in means follow a skewed distribution? Your answer should make reference to the mean, median, and histogram of the differences in means.**

```{r}
mean(pen.boot$t)
median(pen.boot$t)
```
I don't think the resampled differences are skewed. In fact, based on the histogram, the distribution looks like a normal curve centered around the mean, -5.87, which is almost the same as the median, -5.88. 

**Q5 (2 pts.): Show the R-code you used to create pen_ecdf()**
```{r}
pen_ecdf <- ecdf(pen.boot$t)
```

**Q6 (2 pts.): What is the probability, according to the empirical distribution function, of observing a mean difference of -4.5 or greater? Show the R code you used to perform the calculation.**

```{r}
1-pen_ecdf(-4.5)
```

**Q7 (2 pts.): What is the probability, according to the empirical distribution function, of observing a mean difference of -8 or smaller? Show the R code you used to perform the calculation.**

```{r}
pen_ecdf(-8)
```
**Q8 (3 pts.): State the null and alternative hypotheses of a two-sample, two-tailed test for the difference in mean flipper lengths between the two penguin species.**

Null: There is no difference in mean flipper length between Adelie and Chinstrap penguins.

Alternative: There is no difference in mean flipper length between Adelie and Chinstrap penguins.

**Q9 (2 pts.): What was the p-value? Show the R-code you used to find out.**

```{r}
require(here)
treedat <- read.csv(here("data", "vegdata.csv"))
dat_tree = droplevels(subset(treedat, treatment %in% c("control", "clipped")))
wilcox.test(pine ~ treatment, dat = dat_tree)
```
**Q10 (1 pt.): What were the endpoints of your bootstrap CI? Show the R-code you used to find out.**

```{r}
require(boot)
require(simpleboot)
pine <- subset(dat_tree, select = -c(birch, fern))

pinecontrol <- droplevels(subset(pine, treatment =="control"))
pineclipped <-droplevels(subset(pine, treatment =="clipped"))
pinecon <- na.omit(pinecontrol)
pineclip <- na.omit(pineclipped)

tree_boot <- 
  two.boot(pinecon$pine, pineclip$pine, mean, R = 10000, student = FALSE, weights = NULL)

boot.ci(tree_boot)
quantile(tree_boot$t, na.rm = TRUE, c(0.025, 0.975))
```

**Q11 (1 pt.): What is the observed difference in mean tree counts and does it fall within the 95% bootstrap CI?**

-16. This does fall within the confidence interval.

**Q12 (2 pts.): Briefly describe the Simpson diversity index, and explain what it quantifies.**

Simpson's diversity index is a way to measure both community-level diversity and larger metrics of biodiversity. Higher values (i.e. close to 1), indicate greater diversity, while lower values (close to 0) indicate reduced diversity. 

**Q13 (2 pts.): Show the code you used to z-standardize the s.sidi column.**

```{r}
require(here)
dat_bird = read.csv(here("data", "bird.sub.csv"))
head(dat_bird)
dat_hab = read.csv(here("data", "hab.sub.csv"))
head(dat_hab)
dat_all = merge(
  dat_bird, 
  dat_hab,
  by = c("basin", "sub"))
s_sidi_mean = mean(dat_all$s.sidi, na.rm = TRUE)
s_sidi_sd   = sd(dat_all$s.sidi, na.rm = TRUE)
dat_all$s.sidi.standardized = (dat_all$s.sidi - s_sidi_mean)/s_sidi_sd
mean(dat_all$s.sidi.standardized)
sd(dat_all$s.sidi.standardized)
```

**Q14 (6 pts.): Show the code for your completed Monte Carlo simulation loop.**
```{r}
dat_1 = 
  subset(
    dat_all,
    select = c(b.sidi, s.sidi))
m = 10000
result_mc = numeric(m)
for(i in 1:m)
 {  
  index_1 = sample(nrow(dat_1), replace = TRUE)
    index_2 = sample(nrow(dat_1), replace = TRUE)
    dat_resampled_i =
        data.frame(
           b.sidi = dat_1$b.sidi[index_1],
            s.sidi = dat_1$s.sidi[index_2]
          )
    fit_resampled_i = lm(b.sidi ~ s.sidi, data = dat_resampled_i)
    result_mc[i] = coef(fit_resampled_i)[2]
  }

quantile(result_mc, c(.05))
```
**Q15 (2 pts.): In your report, include a plot of your histogram of Monte Carlo resampled slopes. Include vertical lines showing the observed slope and the critical value from the resampled MC slopes.**

```{r echo=TRUE}
fit_1 = lm(b.sidi ~ s.sidi, data = dat_all)
coef(fit_1)
slope_observed = coef(fit_1)[2]
hist(result_mc,
  main = "Elyse's Null Distribution of Regression Slope",
  xlab = "Slope Parameter")
abline(v = slope_observed, col = "blue")
abline(v = -0.0128, lty = 2, col = "red", lwd = 2)
```

**Q16 (2 pts.): What was your critical value? Was the observed slope less than the critical value?**

The critical value was -0.0128. The observed slope was less than the critical value (less than -0.02).

**Q17 (3 pts.): What is your conclusion regarding the evidence of a negative relationship between vegetation cover diversity and bird diversity? Make sure to justify your conclusions using the results of your simulation analysis.**

There is a relationship between bird diversity and vegetation diversity. Since Monte Carlo sampling tests for the null hypothesis, Monte Carlo would show the likelihood of no relationship, indicating that there's no difference between them. However, that's not what we see in this analysis. Here, we see that the observed slope (in blue on the histogram) is much farther left than the critical value's 5% alpha (in red on the histogram). This means that the observed slope is different than the critical value, indicating the null hypothesis is not supported.

**Q18 (2 pts.): Show the code you used in your bootstrap loop.**

```{r}
set.seed(345)
index_1 = sample(nrow(dat_1), replace = TRUE)

dat_boot = dat_1[index_1, ]
head(dat_boot)

m1 = 10000
result_boot = numeric(m1)
for(i in 1:m1)
{
  index_1 = sample(nrow(dat_1), replace = TRUE)
  
  dat_boot = dat_1[index_1, ]
  
  fit_bs1 = lm(b.sidi ~ s.sidi, data = dat_boot)
  result_boot[i] = coef(fit_bs1)[2]
}

fit_bs1 = lm(b.sidi ~ s.sidi, data = dat_boot)

coef(fit_bs1)
```

**Q19 (4 pts.): Include your double density plot. For full credit your plot must include: a legend, the two density curves, in different colors appropriate axis labels and title**

```{r echo=TRUE}
plot(
  density(result_mc),
  main = "Elyse's Null and Alternative Distribution Density Plot",
  xlab = "Slope Coefficient",
  col = "skyblue",
  xlim = c(-0.05,0.05),
  ylim = c(0,70))

lines(
  density(result_boot), col = "deeppink")
  
legend(
  x = "topright",         
  legend = c("null", "alternative"),  
  col = c("skyblue", "deeppink"),
  lty = c(1, 1),
  lwd = 2,
  bty = "n")      
```

**Q20 (2 pts.): Recall that the bootstrap curve shows the distribution of plausible values for the slope coefficient if we could resample the original data. The Monte Carlo curve shows the distribution of plausible values for the slope coefficient if the null hypothesis were true. How can you interpret the region that falls under both curves?**

The region between the two curves shows where type I (where you reject the null hypothesis when it's true) and type II error (when you do not reject a false null hypothesis) occur. Anything that falls under both curves is something you may interpret incorrectly due to these errors, and your conclusion (fail to reject/rejection) of your hypothesis is likely wrong. 




